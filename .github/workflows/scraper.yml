name: scraper

on:
  repository_dispatch:
  schedule:
    # 0th min, 5th hour (5:00 UTC time = 0:00 EST), every 1st and 4th day of each week (Mon/Thu)
    - cron: '0 5 * * 1,4'

jobs:
  prepare-matrix:
    runs-on: ubuntu-latest
    continue-on-error: false
    outputs:
      matrix: ${{ steps.gen-matrix.outputs.matrix }}
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2.3.4
      - id: gen-matrix
        name: Generate matrix for scrape step
        run: echo ::set-output name=matrix::$(sh ./scripts/create-matrix.sh)
  scrape:
    needs: prepare-matrix
    runs-on: ubuntu-latest
    continue-on-error: true
    strategy:
      matrix: ${{ fromJson(needs.prepare-matrix.outputs.matrix) }}
      max-parallel: 7
      fail-fast: false
    services:
      # create a splash service for rendering JS pages (and disable private mode)
      splash:
        image: docker.pkg.github.com/GursahajKohli/SeleniumVector/splash-disable-private:1.0
        credentials:
          username: ${{ github.repository }}
          password: ${{ github.token }}
        ports:
          - 8050:8050
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2.3.4
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      # TODO: cache virtualenv instead of pip packages?
      - name: Cache pip
        id: cache-pip
        uses: actions/cache@v2
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r src/requirements.txt
      - name: Run scraper
        run: |
          cd src/scraper
          python scraper ../../config/scraper/${SITE}.scraper.config ../../out/${SITE}.csv
        env:
          SITE: ${{ matrix.site }}
      - name: Archive CSV outputs
        uses: actions/upload-artifact@v2
        with:
          name: csv-output
          path: ./out/
          if-no-files-found: error
  filter-and-merge:
    runs-on: ubuntu-latest
    needs: scrape
    steps:
      - name: Checkout repository
        uses: actions/checkout@v2.3.4
      - name: Download scraped CSV output
        uses: actions/download-artifact@v2
        with:
          name: csv-output
          path: ./out/
      - name: Setup python
        uses: actions/setup-python@v2
        with:
          python-version: 3.8
      # TODO: cache virtualenv instead of pip packages?
      - name: Cache pip
        id: cache-pip
        uses: actions/cache@v2
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r src/requirements.txt
      - name: Run filter
        run: |
          cd src
          python filter.py ../config/filter/ "../out/*.csv"
      - name: Archive filtered CSVs
        uses: actions/upload-artifact@v2
        with:
          name: filtered-csv-output
          path: ./out/
          if-no-files-found: error
      - name: Run merger
        run: |
          cd src/scraper/scraper
          python merger.py "../../../out/td.csv" ../../../td.xml
          rm ../../../out/td.csv
          python merger.py "../../../out/google.csv" ../../../google.xml
          rm ../../../out/google.csv
          python merger.py "../../../out/loblaw.csv" ../../../loblaw.xml
          rm ../../../out/loblaw.csv
          python merger.py "../../../out/rbc.csv" ../../../rbc.xml
          rm ../../../out/rbc.csv
          python merger.py "../../../out/accenture.csv" ../../../accenture.xml
          rm ../../../out/accenture.csv
          python merger.py "../../../out/*.csv" ../../../merged.xml
      - name: Archive XMLs
        uses: actions/upload-artifact@v2
        with:
          name: xml-output
          path: ./*.xml
          if-no-files-found: error
      # stash ./*.xml --> checkout gh-pages --> apply stash by overwriting (using cherrypick) --> commit
      - name: Commit XMLs on gh-pages
        run: |
          git fetch --all
          git config --local user.email "actions@github.com"
          git config --local user.name "GitHub Action"
          git add ./*.xml
          git stash push -m xmls ./*.xml
          git checkout gh-pages
          git pull origin gh-pages --rebase
          git cherry-pick -n -m1 -Xtheirs stash
          git commit -m "Update XMLs"
      - name: Push changes
        uses: ad-m/github-push-action@v0.6.0
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          branch: gh-pages
